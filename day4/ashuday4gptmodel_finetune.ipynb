{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsXj-Ap48R-U",
        "outputId": "cf0d807e-4e51-4959-eea5-b073bdde5cd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.10.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.7.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Collecting gradio\n",
            "  Downloading gradio-4.40.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.112.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.2.0 (from gradio)\n",
            "  Downloading gradio_client-1.2.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.5)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.5.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.5-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.2.0->gradio) (2024.6.1)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.2.0->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-4.40.0-py3-none-any.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.2.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.6/318.6 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading ruff-0.5.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.30.5-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.112.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, tomlkit, semantic-version, ruff, python-multipart, orjson, h11, ffmpy, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.13.0\n",
            "    Uninstalling tomlkit-0.13.0:\n",
            "      Successfully uninstalled tomlkit-0.13.0\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.112.0 ffmpy-0.4.0 gradio-4.40.0 gradio-client-1.2.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 orjson-3.10.6 pydub-0.25.1 python-multipart-0.0.9 ruff-0.5.6 semantic-version-2.10.0 starlette-0.37.2 tomlkit-0.12.0 uvicorn-0.30.5 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "# data model format for GPT\n",
        "# ROle specific\n",
        "# we have to prepara training data with few examples\n",
        "# single sample data 1 data of example\n",
        "# {\n",
        "#     \"messages\": [\n",
        "#         { \"role\": \"system\" , \"content\": \"my hotel bot which is helping customer untill they are not satified\" },\n",
        "#         { \"role\": \"user\" , \"content\": \"i can't find wifi password\" },\n",
        "#         { \"role\": \"assistant\" , \"content\": \"hey sorry for inconvience but wifi passsword you have to just ask at reception\" }\n",
        "#     ],\n",
        "#     \"messages\": [\n",
        "#         { \"role\": \"system\" , \"content\": \"my hotel bot which is helping customer untill they are not satified\" },\n",
        "#         { \"role\": \"user\" , \"content\": \"i need to order food where is the menu \" },\n",
        "#         { \"role\": \"assistant\" , \"content\": \"there must be a table in you room check there else please call 9 extension\" }\n",
        "#     ]\n",
        "# }\n",
        "!pip install openai==0.28\n",
        "!pip install numpy gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import json\n",
        "import openai\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import gradio as gr\n"
      ],
      "metadata": {
        "id": "EfF-RCLAXvCx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load api Key\n",
        "openai.api_key = \"\""
      ],
      "metadata": {
        "id": "h-599iPwk6M2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets list models what we have already fine tuned and free FM in my account\n",
        "response = openai.Model.list()\n",
        "# listing all the models assoicated with my accont\n",
        "#print(response['data'])\n",
        "# only priting model id\n",
        "for model_id in response['data']:\n",
        "    print(model_id['id'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOVZanBDM9a6",
        "outputId": "1898f9fc-80b0-4fec-8b77-9cebb22195a6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dall-e-3\n",
            "gpt-4-1106-preview\n",
            "dall-e-2\n",
            "tts-1-hd-1106\n",
            "tts-1-hd\n",
            "text-embedding-3-large\n",
            "gpt-4-0125-preview\n",
            "babbage-002\n",
            "gpt-4-turbo-preview\n",
            "gpt-4o\n",
            "gpt-4o-2024-05-13\n",
            "text-embedding-3-small\n",
            "tts-1\n",
            "gpt-3.5-turbo\n",
            "whisper-1\n",
            "text-embedding-ada-002\n",
            "gpt-3.5-turbo-16k\n",
            "davinci-002\n",
            "gpt-4-turbo-2024-04-09\n",
            "tts-1-1106\n",
            "gpt-3.5-turbo-0125\n",
            "gpt-4-turbo\n",
            "gpt-3.5-turbo-1106\n",
            "gpt-3.5-turbo-instruct-0914\n",
            "gpt-4o-2024-08-06\n",
            "gpt-3.5-turbo-instruct\n",
            "gpt-4-0613\n",
            "gpt-4\n",
            "gpt-4o-mini-2024-07-18\n",
            "gpt-4o-mini\n",
            "ft:gpt-3.5-turbo-0125:personal:rm-hotel-bot:9tfsed6j:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:rm-hotel-bot:9tfser6x:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:rm-hotel-bot:9tfseTjI\n",
            "ft:gpt-3.5-turbo-0125:personal:training-hote-bot:9toCJCtO:ckpt-step-32\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-walmartbot:9tVvJxZA:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-walmartbot:9tVvJe6E:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-walmartbot:9tVvJ5oT\n",
            "ft:gpt-3.5-turbo-0125:personal:samantha-test:9tW4MOZd\n",
            "ft:gpt-3.5-turbo-0125:personal:training-hote-bot:9toCJ5qr:ckpt-step-64\n",
            "ft:gpt-3.5-turbo-0125:personal:training-hote-bot:9toCJjSC\n",
            "ft:gpt-3.5-turbo-0125:personal:samantha-test:9tW4MFcG:ckpt-step-114\n",
            "ft:gpt-3.5-turbo-0125:personal:samantha-test:9tW4MwCX:ckpt-step-57\n",
            "ft:gpt-3.5-turbo-0125:personal:manish-walmart-bot:9toOPoTV:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:manish-walmart-bot:9toOP89p:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:manish-walmart-bot:9toOP155\n",
            "ft:gpt-3.5-turbo-0125:personal:hotel-bot:9teGNfPK:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:hotel-bot:9teGNgSX:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:hotel-bot:9teGN9Gl\n",
            "ft:gpt-3.5-turbo-0125:personal:hotel-bot:9teHDHFw:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:hotel-bot:9teHDG2a:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:hotel-bot:9teHEIQa\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9teHfpnU:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9teHgqf9:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9teHgxTA\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9tf25vvY:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:chatner-bot:9t3xDPIC:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:chatner-bot:9t3xDQOW:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:chatner-bot:9t3xDM1s\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9tf24xX5:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9tf25WXg\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJBnwBd:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJHvgu0:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9tJ5jMgn:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9tJ5j93I:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9tJ5j4qV\n",
            "ft:gpt-3.5-turbo-0125:personal:ps-hotel-bot:9tJ7Du6I:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:ps-hotel-bot:9tJ7EmiE:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:ps-hotel-bot:9tJ7Ef0a\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJHwsIv\n",
            "ft:gpt-3.5-turbo-0125:personal::9tJ7yW3o:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal::9tJ7y0Rm:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal::9tJ7yuLr\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJBngi4:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJBn1K9\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJE5Yl0:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJE6Or6:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJE6IEC\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJHvCpQ:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:sekhar-hotel-bot:9tJQE02x\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJEuQ02:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJEudsN:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJEuzKM\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9tJJJwbk:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9tJJKsQU:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9tJJKZnD\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJJNpyu:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJJOrRZ:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJJO9P1\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJK0TRr:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJK0Kiv:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJK0A4Z\n",
            "ft:gpt-3.5-turbo-0125:personal:sekhar-hotel-bot:9tJQDSNT:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:sekhar-hotel-bot:9tJQDhTy:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:zac-hotel-bot:9tJYflyv:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:zac-hotel-bot:9tJYg1Sf:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:zac-hotel-bot:9tJYga2M\n",
            "ft:gpt-3.5-turbo-0125:personal:rm-hotel-bot:9tJb5xcj:ckpt-step-18\n",
            "ft:gpt-3.5-turbo-0125:personal:rm-hotel-bot:9tJb5aZk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# asking query from FM about hotel data which we trained on\n",
        "# testing model\n",
        "# creating funcation\n",
        "def ashu_fmtune(user_input):\n",
        "  ashu_test_message = []\n",
        "  # refering system message\n",
        "\n",
        "  system_message = \"You are an overly friendly hospitality chatbot named Chatner who just loves to help people, and you're not satisfied unless the customer is completely satisfied.\"\n",
        "  ashu_test_message.append({ \"role\": \"system\" , \"content\": system_message})\n",
        "  #user_input = \"hey i am will to watch movie in my laptop on netflix but i dont' have internet access\"\n",
        "\n",
        "  ashu_test_message.append({ \"role\": \"user\" , \"content\": user_input})\n",
        "\n",
        "  # printing input\n",
        "  print(ashu_test_message)\n",
        "\n",
        "  # calling any fine tuned from above list to response my query\n",
        "  # Create a chat completion request using the fine-tuned model\n",
        "  ashu_response = openai.ChatCompletion.create(\n",
        "      model=\"ft:gpt-3.5-turbo-0125:personal:ashu-walmartbot:9tVvJxZA:ckpt-step-54\",  # Ensure this is a string with your model ID\n",
        "      messages=ashu_test_message,  # Use the prepared messages list\n",
        "      temperature=0.1, # hyper parameter we can adjust it to get more creative response\n",
        "      max_tokens=400\n",
        "  )\n",
        "\n",
        "\n",
        "  print(\"ashutoshh fine tuned FM response ........>>\")\n",
        "  print(\"#$##############\")\n",
        "  return ashu_response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "# creating gradio interface\n",
        "my_interface = gr.Interface(\n",
        "    fn=ashu_fmtune,\n",
        "    inputs=gr.Textbox(label=\"Type your Query \"),\n",
        "    outputs=gr.Textbox(label=\"Response  \"),\n",
        "    title=\" Hotel chatbot interface \"\n",
        "    )\n",
        "\n",
        "# calling\n",
        "my_interface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "Y_YoEQ2uOi5-",
        "outputId": "ed51dbbe-bfcc-4ce7-8c98-98bea632f069"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://d7f69a2dcc7c835614.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d7f69a2dcc7c835614.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # loading and cleaning of data\n",
        "# ashudata_path = \"/content/sample_data/hotel_hospitality_data.csv\"\n",
        "\n",
        "# cleaned_data = []\n",
        "\n",
        "# with open(ashudata_path, 'r', encoding='utf-8-sig') as file:\n",
        "#     csv_reader = csv.reader(file)\n",
        "#     for row in csv_reader:\n",
        "#         for cell in row:\n",
        "#             try:\n",
        "#                 # Replace square brackets and inner double quotes that are problematic\n",
        "#                 cell = cell.replace('[\"', '').replace('\"]', '').replace('\\\"', '\"')\n",
        "\n",
        "#                 # Load each cell as a JSON object\n",
        "#                 cell_json = json.loads(cell)\n",
        "\n",
        "#                 # Now that the content is clean, append to cleaned_data list\n",
        "#                 cleaned_data.append(cell_json)\n",
        "#             except json.JSONDecodeError as e:\n",
        "#                 print(f\"JSON decode error for cell '{cell}': {e}\")\n",
        "\n",
        "# printing clean data\n",
        "#print(cleaned_data[0])\n",
        "# save data into jsonl format\n",
        "# ashudata_jsonl_path = \"/content/sample_data/ashuhotel_hospitality_data.jsonl\"\n",
        "# with open(ashudata_jsonl_path,'w',encoding='utf-8-sig') as f1:\n",
        "#   for data in cleaned_data:\n",
        "#     f1.write(json.dumps(data) + '\\n')"
      ],
      "metadata": {
        "id": "a7xEGOqUDGwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # take 2 or 3 minutes then drop done message\n",
        "# # validate /\n",
        "# ashudata_jsonl_path1 = \"/content/sample_data/ashuhotel_hospitality_data.jsonl\"\n",
        "\n",
        "# with open(ashudata_jsonl_path1, 'r',encoding='utf-8-sig') as f2:\n",
        "#    mydataset = [json.loads(i) for i in f2]\n",
        "\n",
        "# # checking lengh\n",
        "# print(\"mydataset length is \",len(mydataset))\n",
        "# print(\"first example \")\n",
        "# for i in mydataset[0][\"messages\"]:\n",
        "#   print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HGfX76xW74L",
        "outputId": "126f6bcc-899a-414d-85cb-d71dd95b7d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mydataset length is  18\n",
            "first example \n",
            "{'role': 'system', 'content': \"You are an overly friendly hospitality chatbot named Chatner who just loves to help people, and you're not satisfied unless the customer is completely satisfied.\"}\n",
            "{'role': 'user', 'content': 'Where is the gym located?'}\n",
            "{'role': 'assistant', 'content': \"Our gym is located on the 2nd floor. I'll be happy to show you the way if you need help!\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# format validation\n",
        "# Format error checks\n",
        "# format_errors = defaultdict(int)\n",
        "\n",
        "# for ex in mydataset:\n",
        "#     if not isinstance(ex, dict):\n",
        "#         format_errors[\"data_type\"] += 1\n",
        "#         continue\n",
        "\n",
        "#     messages = ex.get(\"messages\", None)\n",
        "#     if not messages:\n",
        "#         format_errors[\"missing_messages_list\"] += 1\n",
        "#         continue\n",
        "\n",
        "#     for message in messages:\n",
        "#         if \"role\" not in message or \"content\" not in message:\n",
        "#             format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "#         if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
        "#             format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "#         if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
        "#             format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "#         content = message.get(\"content\", None)\n",
        "#         function_call = message.get(\"function_call\", None)\n",
        "\n",
        "#         if (not content and not function_call) or not isinstance(content, str):\n",
        "#             format_errors[\"missing_content\"] += 1\n",
        "\n",
        "#     if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "#         format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "# if format_errors:\n",
        "#     print(\"Found errors:\")\n",
        "#     for k, v in format_errors.items():\n",
        "#         print(f\"{k}: {v}\")\n",
        "# else:\n",
        "#     print(\"No errors found\")"
      ],
      "metadata": {
        "id": "k3yuINc6hWdk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b46e708f-6de0-4da6-abbc-423efcacdf56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # upload validated to gpt hosted server\n",
        "# ashu_training = openai.File.create(\n",
        "#     file=open(ashudata_jsonl_path1,\"rb\"),\n",
        "#     purpose=\"fine-tune\")\n",
        "# # display details\n",
        "# print(ashu_training)\n",
        "# # pick file id\n",
        "# ashu_file_id = ashu_training[\"id\"]\n",
        "# print(\"ashutoshh fine tune data file id is \",ashu_file_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm0RlMv1PWeG",
        "outputId": "3a02850c-4554-4760-a37d-1dcd0b435e74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"object\": \"file\",\n",
            "  \"id\": \"file-pAewQamlwNemgGd1DG8JyL3S\",\n",
            "  \"purpose\": \"fine-tune\",\n",
            "  \"filename\": \"file\",\n",
            "  \"bytes\": 7555,\n",
            "  \"created_at\": 1723007689,\n",
            "  \"status\": \"processed\",\n",
            "  \"status_details\": null\n",
            "}\n",
            "ashutoshh fine tune data file id is  file-pAewQamlwNemgGd1DG8JyL3S\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fine tuning model with custom uploaded data\n",
        "# # GPT models -- are limited\n",
        "# ashu_model_name = \"ashu_walmartbot\"\n",
        "# ashu_model_response = openai.FineTuningJob.create(\n",
        "#     training_file=ashu_file_id,\n",
        "#     suffix=ashu_model_name,\n",
        "#     model=\"gpt-3.5-turbo\"\n",
        "# )\n",
        "# # printing fine tuned model id\n",
        "# print(ashu_model_response)\n",
        "\n",
        "# ashu_fm_final_model_id = ashu_model_response[\"id\"]\n",
        "# print(ashu_fm_final_model_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyeXLHp0S0Tf",
        "outputId": "6add8d93-8cd1-4026-a23e-1fd934e2c111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"object\": \"fine_tuning.job\",\n",
            "  \"id\": \"ftjob-KiAK2Ap5SVrV66Z5mBQEAPSM\",\n",
            "  \"model\": \"gpt-3.5-turbo-0125\",\n",
            "  \"created_at\": 1723011271,\n",
            "  \"finished_at\": null,\n",
            "  \"fine_tuned_model\": null,\n",
            "  \"organization_id\": \"org-sW9LYXODuBOJUwL7Lo4RNLZu\",\n",
            "  \"result_files\": [],\n",
            "  \"status\": \"validating_files\",\n",
            "  \"validation_file\": null,\n",
            "  \"training_file\": \"file-pAewQamlwNemgGd1DG8JyL3S\",\n",
            "  \"hyperparameters\": {\n",
            "    \"n_epochs\": \"auto\",\n",
            "    \"batch_size\": \"auto\",\n",
            "    \"learning_rate_multiplier\": \"auto\"\n",
            "  },\n",
            "  \"trained_tokens\": null,\n",
            "  \"error\": {},\n",
            "  \"user_provided_suffix\": \"ashu_walmartbot\",\n",
            "  \"seed\": 239882505,\n",
            "  \"estimated_finish\": null,\n",
            "  \"integrations\": []\n",
            "}\n",
            "ftjob-KiAK2Ap5SVrV66Z5mBQEAPSM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # listing job process\n",
        "# ashu_process = openai.FineTuningJob.list_events(id=ashu_fm_final_model_id ,limit=50)\n",
        "# ashu_events = ashu_process[\"data\"]\n",
        "# ashu_events.reverse()\n",
        "# for msg in ashu_events:\n",
        "#   print(msg[\"message\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psQvulsJdCP9",
        "outputId": "bc0aea40-5865-43f8-a026-72f9695eda4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 46/90: training loss=0.17\n",
            "Step 47/90: training loss=0.43\n",
            "Step 48/90: training loss=0.34\n",
            "Step 49/90: training loss=0.39\n",
            "Step 50/90: training loss=0.43\n",
            "Step 51/90: training loss=0.14\n",
            "Step 52/90: training loss=0.22\n",
            "Step 53/90: training loss=0.14\n",
            "Step 54/90: training loss=0.39\n",
            "Step 55/90: training loss=0.50\n",
            "Step 56/90: training loss=0.22\n",
            "Step 57/90: training loss=0.36\n",
            "Step 58/90: training loss=0.09\n",
            "Step 59/90: training loss=0.16\n",
            "Step 60/90: training loss=0.25\n",
            "Step 61/90: training loss=0.80\n",
            "Step 62/90: training loss=0.28\n",
            "Step 63/90: training loss=0.21\n",
            "Step 64/90: training loss=0.05\n",
            "Step 65/90: training loss=0.07\n",
            "Step 66/90: training loss=0.39\n",
            "Step 67/90: training loss=0.22\n",
            "Step 68/90: training loss=0.19\n",
            "Step 69/90: training loss=0.07\n",
            "Step 70/90: training loss=0.50\n",
            "Step 71/90: training loss=0.14\n",
            "Step 72/90: training loss=0.12\n",
            "Step 73/90: training loss=0.32\n",
            "Step 74/90: training loss=0.45\n",
            "Step 75/90: training loss=0.04\n",
            "Step 76/90: training loss=0.66\n",
            "Step 77/90: training loss=0.03\n",
            "Step 78/90: training loss=0.10\n",
            "Step 79/90: training loss=0.16\n",
            "Step 80/90: training loss=0.11\n",
            "Step 81/90: training loss=0.12\n",
            "Step 82/90: training loss=0.26\n",
            "Step 83/90: training loss=0.22\n",
            "Step 84/90: training loss=0.37\n",
            "Step 85/90: training loss=0.12\n",
            "Step 86/90: training loss=0.04\n",
            "Step 87/90: training loss=0.12\n",
            "Step 88/90: training loss=0.03\n",
            "Step 89/90: training loss=0.08\n",
            "Step 90/90: training loss=0.26\n",
            "Checkpoint created at step 54 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:ashu-walmartbot:9tUYd7pN:ckpt-step-54\n",
            "Checkpoint created at step 72 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal:ashu-walmartbot:9tUYdePs:ckpt-step-72\n",
            "New fine-tuned model created: ft:gpt-3.5-turbo-0125:personal:ashu-walmartbot:9tUYeBXK\n",
            "Evaluating model against our usage policies before enabling.\n",
            "The job has successfully completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing model\n",
        "ashu_test_message = []\n",
        "# refering system message\n",
        "\n",
        "system_message = \"You are an overly friendly hospitality chatbot named Chatner who just loves to help people, and you're not satisfied unless the customer is completely satisfied.\"\n",
        "ashu_test_message.append({ \"role\": \"system\" , \"content\": system_message})\n",
        "user_input = \"hey i am unable to find wifi password\"\n",
        "\n",
        "ashu_test_message.append({ \"role\": \"user\" , \"content\": user_input})\n",
        "\n",
        "# printing input\n",
        "print(ashu_test_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO7iV-JJlps_",
        "outputId": "253b9315-7be5-4a2c-dc17-b968749fb312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'system', 'content': \"You are an overly friendly hospitality chatbot named Chatner who just loves to help people, and you're not satisfied unless the customer is completely satisfied.\"}, {'role': 'user', 'content': 'hey i am unable to find wifi password'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# retrive model id\n",
        "ashu_id_response = openai.FineTuningJob.retrieve(ashu_fm_final_model_id)\n",
        "print(ashu_id_response)\n",
        "# geting fine tune model id\n",
        "real_ashu_model_finetID = ashu_id_response[\"fine_tuned_model\"]\n",
        "print(\"my fine tuned model id is \",real_ashu_model_finetID)\n",
        "print(type(real_ashu_model_finetID))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRRO1IHCpzQZ",
        "outputId": "a3b0c800-4a53-45fd-f66b-780abfde77b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"object\": \"fine_tuning.job\",\n",
            "  \"id\": \"ftjob-KiAK2Ap5SVrV66Z5mBQEAPSM\",\n",
            "  \"model\": \"gpt-3.5-turbo-0125\",\n",
            "  \"created_at\": 1723011271,\n",
            "  \"finished_at\": 1723012530,\n",
            "  \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0125:personal:ashu-walmartbot:9tUYeBXK\",\n",
            "  \"organization_id\": \"org-sW9LYXODuBOJUwL7Lo4RNLZu\",\n",
            "  \"result_files\": [\n",
            "    \"file-lXUab6SJA3fYxerKXK9zEHbn\"\n",
            "  ],\n",
            "  \"status\": \"succeeded\",\n",
            "  \"validation_file\": null,\n",
            "  \"training_file\": \"file-pAewQamlwNemgGd1DG8JyL3S\",\n",
            "  \"hyperparameters\": {\n",
            "    \"n_epochs\": 5,\n",
            "    \"batch_size\": 1,\n",
            "    \"learning_rate_multiplier\": 2\n",
            "  },\n",
            "  \"trained_tokens\": 6695,\n",
            "  \"error\": {},\n",
            "  \"user_provided_suffix\": \"ashu_walmartbot\",\n",
            "  \"seed\": 239882505,\n",
            "  \"estimated_finish\": null,\n",
            "  \"integrations\": []\n",
            "}\n",
            "my fine tuned model id is  ft:gpt-3.5-turbo-0125:personal:ashu-walmartbot:9tUYeBXK\n",
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Model.list()\n",
        "\n",
        "for model in response['data']:\n",
        "    print(model['id'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygFqzkMtuErt",
        "outputId": "494d8d56-7d9f-47ab-b2c0-ef61e1bb8756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dall-e-3\n",
            "gpt-4-1106-preview\n",
            "dall-e-2\n",
            "tts-1-hd-1106\n",
            "tts-1-hd\n",
            "text-embedding-3-large\n",
            "gpt-4-0125-preview\n",
            "babbage-002\n",
            "gpt-4-turbo-preview\n",
            "gpt-4o\n",
            "gpt-4o-2024-05-13\n",
            "text-embedding-3-small\n",
            "tts-1\n",
            "gpt-3.5-turbo\n",
            "whisper-1\n",
            "gpt-4o-2024-08-06\n",
            "text-embedding-ada-002\n",
            "gpt-3.5-turbo-16k\n",
            "davinci-002\n",
            "gpt-4-turbo-2024-04-09\n",
            "tts-1-1106\n",
            "gpt-3.5-turbo-0125\n",
            "gpt-4-turbo\n",
            "gpt-3.5-turbo-1106\n",
            "gpt-3.5-turbo-instruct-0914\n",
            "gpt-3.5-turbo-instruct\n",
            "gpt-4o-mini-2024-07-18\n",
            "gpt-4o-mini\n",
            "gpt-4-0613\n",
            "gpt-4\n",
            "ft:gpt-3.5-turbo-0125:personal:chatner-bot:9t3xDPIC:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:chatner-bot:9t3xDQOW:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:chatner-bot:9t3xDM1s\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJBnwBd:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJHvgu0:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9tJ5jMgn:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9tJ5j93I:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9tJ5j4qV\n",
            "ft:gpt-3.5-turbo-0125:personal:ps-hotel-bot:9tJ7Du6I:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:ps-hotel-bot:9tJ7EmiE:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:ps-hotel-bot:9tJ7Ef0a\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJHwsIv\n",
            "ft:gpt-3.5-turbo-0125:personal::9tJ7yW3o:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal::9tJ7y0Rm:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal::9tJ7yuLr\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJBngi4:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJBn1K9\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJE5Yl0:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJE6Or6:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJE6IEC\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJHvCpQ:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:sekhar-hotel-bot:9tJQE02x\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJEuQ02:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJEudsN:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJEuzKM\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9tJJJwbk:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9tJJKsQU:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9tJJKZnD\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJJNpyu:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJJOrRZ:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJJO9P1\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJK0TRr:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJK0Kiv:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJK0A4Z\n",
            "ft:gpt-3.5-turbo-0125:personal:sekhar-hotel-bot:9tJQDSNT:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:sekhar-hotel-bot:9tJQDhTy:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:zac-hotel-bot:9tJYflyv:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:zac-hotel-bot:9tJYg1Sf:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:zac-hotel-bot:9tJYga2M\n",
            "ft:gpt-3.5-turbo-0125:personal:rm-hotel-bot:9tJb5xcj:ckpt-step-18\n",
            "ft:gpt-3.5-turbo-0125:personal:rm-hotel-bot:9tJb5aZk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# asking fine tuned model to give response of above question\n",
        "# Create a chat completion request using the fine-tuned model\n",
        "ashu_response = openai.ChatCompletion.create(\n",
        "    model=\"ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJJNpyu:ckpt-step-54\",  # Ensure this is a string with your model ID\n",
        "    messages=ashu_test_message,  # Use the prepared messages list\n",
        "    temperature=0,\n",
        "    max_tokens=400\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(ashu_response)\n",
        "# original message\n",
        "ashu_response[\"choices\"][0][\"message\"][\"content\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "g8A4XWz8nVa-",
        "outputId": "366d4681-358c-4a9e-803c-1160f38ac113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-9tVMrYw7Gycuawi7ibUhr3m6c6Ubl\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1723015645,\n",
            "  \"model\": \"ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJJNpyu:ckpt-step-54\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"No problem! The WiFi password is \\\"Welcome123\\\". Let me know if you need help with anything else.\",\n",
            "        \"refusal\": null\n",
            "      },\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 49,\n",
            "    \"completion_tokens\": 22,\n",
            "    \"total_tokens\": 71\n",
            "  },\n",
            "  \"system_fingerprint\": null\n",
            "}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'No problem! The WiFi password is \"Welcome123\". Let me know if you need help with anything else.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}